---
title: "Taking a Leap of Faith: Association to Causation"
author: "Lindsey Dietz, PhD"
date: "`r Sys.Date()`"
format: 
  revealjs:
    incremental: true  
    theme: dark
    code-fold: true
    scrollable: true
    progress: true
    fontsize: 2.2em
    slide-number: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Disclaimer

The views expressed in this presentation are strictly my own. They do not necessarily represent the position of the Federal Reserve Bank of Minneapolis or the Federal Reserve System.

## Who am I?

::: columns
::: {.column width="75%"}
-   [Data Science Manager \@ Federal Reserve Bank of Minneapolis](https://www.minneapolisfed.org/news-releases/2021/dietz-recognized-for-excellence-in-bank-supervision)
    -   I lead a team working on implementation and analysis of models for stress testing the largest banks.
-   R Enthusiast and STEM diversity advocate
    -   [Creator of the noRth R user conference](https://rnorthconference.github.io/)
    -   [Co-organizer of the R Ladies - Twin Cities meetup](https://www.meetup.com/rladies-tc/members/)
    -   [IF/THEN AAAS STEM Ambassador](https://www.si.edu/womensfutures)
:::

::: {.column width="25%"}
<center><img src="images/statue.png" width="500"/></center>
:::
:::

# Motivation

## Coffee

How many of you drink coffee?

. . .

How many of you think it is bad for you?

. . .

*"The **risk** of hypertension associated with coffee intake varies according to CYP1A2 genotype. Carriers of slow 1F allele are at **increased risk** and should thus abstain from coffee, whereas individuals with 1A/1A genotype can safely drink coffee."*

-- Journal of Hypertension, August 2009

## Coffee

How many of you drink coffee?

How many of you think it is good for you?

. . .

*"Drinking two to three cups of coffee a day is **linked with a longer lifespan and lower risk** of cardiovascular disease compared with avoiding coffee."*

-- European Journal of Preventive Cardiology, September 2022

##  {background-iframe="https://giphy.com/embed/UnTC9o2HMyUta" background-repeat="a\"repeat\""}

## Agenda

-   Causal Inference Preliminaries
-   Matching
-   Example using R and Airbnb Data

## Association To Causation

-   Most researchers want to understand more than just association (a.k.a links, risks, etc.)
-   For example,
    -   Will a new feature increase revenue in my app?
    -   Does a vaccine prevent the flu?
    -   Will a regulatory policy change impact bank capital?

## Causal Inference

Causal inference is a general set of principles and methods that allow us to make statistical inferences about the causal effects of treatments from randomized and observational data.

## 

*Did she just say I can make causal statements about observational data?*

<center><img src="https://media.giphy.com/media/5SXsDXvfhx2eI/giphy.gif" width="400"/></center>

. . .

Yes, I did, but...

## The 'Leap of Faith'

We must make **strong and mostly untestable** assumptions about the treatment assignment mechanism to go from descriptive to causal inference for observational data.

## Those who can, design experiments!

::: columns
::: {.column width="30%"}
<center><img src="https://media.giphy.com/media/vnELlPo3FyzfO/giphy.gif" width="500"/></center>
:::

::: {.column width="70%"}
-   Randomized Experiments a.k.a *Randomized Controlled Trials (RCTs)* or *A/B testing* are the gold standard for causation.
-   However, ethical or logistical reasons may prevent us from using experimentation.
    -   We cannot force people to do dangerous things.
    -   If one unit is influenced by another, we cannot parse treatment impacts.
:::
:::

# Causal Model

## Neyman--Rubin Causal Model

-   Aside from a randomized experiment, causal inference is a missing data problem.

-   We don't know the real-world probability of a unit being assigned into a treatment ($T$) given a set of confounders ($X$).

## Potential Outcomes Framework

Each unit has *potential* outcomes $\{Y_0, Y_1\}$ before a treatment decisions is made. A *counterfactual* outcome is what would have been observed if the treatment had been different.

![](images/outcomes.png){fig-align="center"}

## Fundamental problem of causal inference

We cannot observe both potential outcomes for a unit.

![](images/observed.png){fig-align="center"}

## Average Treatment Effect (ATE)

Average of all treatment potential outcomes − Average of all control potential outcomes

${ATE} = E[Y_{1} − Y_{0}]$

In general, $E[Y_{1} − Y_{0}] \ne E[Y|T=1] − E[Y|T=0]$.

This is a difference between setting and conditioning (though the notation appears to be identical!)

$E[Y|T=1]$: mean of Y among units with T = 1

$E[Y_1]$: mean of Y if the whole population was treated with T = 1

Key idea: estimating the counterfactual --- a prediction of what would have happened in the absence of the treatment.

## Positivity Assumption

<center><img src="https://media.giphy.com/media/zRwA2JgARLVYgWtfgY/giphy.gif" width="800"/></center>

## Positivity Assumption

-   English: Conditional on confounders, every experimental unit is equally likely to be assigned a treatment.

-   Probabilistic: $P(T = t | X = x) > 0$.

-   Why: If some segment of the population has no chance of being assigned a treatment, there is no counterfactual to estimate.

## Ignorability Assumption

<center><img src="https://media.giphy.com/media/IdmfEtnMWPzOg/giphy.gif" width="1000"/></center>

## Ignorability Assumption

-   English: There are no unmeasured confounders.

-   Probabilistic: $Y_0, Y_1 \perp T | X$.

-   Why: Among those with the same confounders, we can assume the treatment has been randomly assigned.

## Consistency Assumption

<center><img src="https://media.giphy.com/media/fvT2tuQGmYxsQbSrQH/giphy.gif" width="1000"/></center>

## Consistency Assumption

-   English: Each outcome is observable.

-   Probabilistic: $Y = Y_t$ if $T = t$ for all $t$. This implies, $P(Y|T=t) = P(Y_t|T=t)$.

-   Why:

## Stable Unit Treatment Value Assumption (SUTVA)

<center><img src="https://media.giphy.com/media/ailnj2AMt9e9i/giphy.gif" width="800"/></center>

## Stable Unit Treatment Value Assumption (SUTVA)

-   Potential outcomes for unit i are unaffected by the treatment assignment for unit j.

## How assumptions get us to the ATE

```{=tex}
\begin{tabular}{ c | c | c }
Y & T & X \\
 \hline \\
10 & T & X \\
8 & T & X \\
7 & T & X \\
4 & T & X 
\end{tabular}
```
$E[Y|T=t, X=x]$ involves only observed data.

| Unit |   Y |   T | X   |
|-----:|----:|----:|:----|
|    1 |  10 |   1 | 1   |
|    2 |   7 |   1 | 1   |
|    3 |   8 |   0 | 1   |
|    4 |   5 |   0 | 1   |

$E[Y|T=1, X=1] = \frac{10 + 7}{2} = 8.5$ $E[Y|T=0, X=1] = \frac{8 + 5}{2} = 6.5$

## How assumptions get us to the ATE

```{=tex}
\begin{align}
E[Y|T=t, X=x] =& E[Y_t|T=t, X=x] \text{ by Consistency}\\
=& E[Y_t|X=x] \text{ by Ignorability}\\
\end{align}
```
::: fragment
$E[Y_t] = E[E[Y_t|X=x]]$ by the Law of Total Expectation
:::

::: fragment
Then, \begin{align}
E[Y_1 - Y_0] =& E[Y_1] - E[Y_0] \\
=& E[E[Y_1|X=x]] - E[E[Y_0|X=x]]
\end{align}
:::

# Propensity Scores & Matching

## Propensity Scores

-   In a randomized experiment, $P(T=1|X) = P(T=1) = 0.5$.

-   In most observational data sets, there was no random assignment of the treatment $P(T=1|X) = f(X)$. However, we can estimate $f(X)$ with data and assumptions about which $X$ matter.

    -   Ex. a unit with predicted propensity score of 0.3 has a 30% chance of receiving treatment.

-   Once we match on propensity score, we can meet our assumption of *Ignorability*.

## Matching in Practice

1.  Fit a propensity score model for treatment: $P(T=1|X) = f(X)$
    -   Choice of model for a binary outcome such as logistic regression or machine learning alternatives
2.  Apply the model to predict a propensity score for each observation.
3.  Match observations based on a selected algorithm.
    -   Choice of distance to optimize
    -   Choice of maximum distance (caliper)
4.  Use matched outcomes in statistical inference

# R Example

## Airbnb Data Example

Will adding heating in Minneapolis-St. Paul Airbnb listings lead to increased revenue per stay?

-   Treatment: Heating present
-   Control: Heating absent
-   Unit: Unique listing
-   Outcome: Nightly cost
-   Plausible Confounders: reviews per month, \# of bedrooms, \# of bathrooms, type of listing (Private Room vs. Entire home). 

. . .

*Please note there are many many other confounders possible that I'm not including for simplicity.*

## Setting up libraries and reading data

```{r dataclean}
#| message: false
#| code-fold: false

library(dplyr)
library(tidyr)
library(stringr)
library(MatchIt)
library(tableone)
library(data.table)
library(ggplot2)

# Custom functions for this analysis
source('support_functions.R')

# http://insideairbnb.com/get-the-data
msp <- reading_data(url = "http://data.insideairbnb.com/united-states/mn/twin-cities-msa/2022-09-16/data/listings.csv.gz")

```
                      
## Data cleaning and review 

```{r}
#| message: false

# Custom function to get top n amenities for simplicity
top40msp <- top_amenities(data = msp, number = 40) 

# Custom function to apply filters and pre-processing
analysis_set_msp <- create_analysis_set(
                      data = msp, 
                      amenities_vector = top40msp, 
                      test_var = 'Heating',
                      inactive_date = as.Date('2022-04-30'),
                      room_types = c('Entire home/apt', 'Private room'),
                      standard_baths = 1:3,
                      standard_beds = 0:5,
                      review_lower_bound = 0,
                      min_nights_upper_bound = 7)

unmatched_tbl <- tableone::CreateTableOne(
                         vars = c('reviews_per_month', 'beds', 'bathroom', 'room_type'),
                         data = analysis_set_msp, 
                         strata = 'Heating', 
                         smd = TRUE, 
                         test = FALSE)

print(unmatched_tbl, smd = TRUE)

```

## Standardized Mean Difference (SMD)

SMD is a measure of distance between two group means.

-   Continuous variables: $SMD = \frac{\bar{x}_t - \bar{x}_c}{\sqrt{\frac{s_t^2 + s_c^2}{2}}}$

-   Binary variables: $SMD = \frac{\hat{p}_t - \hat{p}_c}{\sqrt{\frac{p_t(1-p_t) + p_c(1-p_c)}{2}}}$

-   Heuristic: SMD \< 0.1 indicates a negligible difference in the mean or prevalence of a covariate between groups.

::: fragment
```{r}
#| message: false
#| echo: false
print(unmatched_tbl, smd = TRUE)

```
:::

## Fit a propensity score model 

```{r propscore2}
#| message: false
#| cache: true

matched_out <- MatchIt::matchit(Heating ~ reviews_per_month + factor(beds) +
                                  factor(bathroom) + factor(room_type), 
                                data = analysis_set_msp, 
                                distance = 'glm',
                                link = 'logit',
                                method = 'optimal',
                                caliper = NULL)

```

. . .

Some variations to consider:

 - Replace method with one of several others: "nearest" will give nearest neighbor a.k.a greedy matching 
 
 - Use a caliper to reduce possible distances eligible for matching

## Matched outputs 

```{r propscorematch}
#| message: false
#| cache: true

final_match <- MatchIt::match.data(matched_out) %>% 
  dplyr::arrange(subclass, desc(Heating)) %>%
  dplyr::rename(prop_score = distance) 
  
final_match %>%
  dplyr::select(subclass, prop_score, price, Heating, beds, bathroom)
```

## Review balance of matching

```{r propscore4}
#| message: false

match_tbl <- tableone::CreateTableOne(
                    vars = c('reviews_per_month', 'beds', 'bathroom', 'room_type'), 
                    data = final_match,
                    strata = 'Heating',
                    smd = TRUE, 
                    test = FALSE)

print(match_tbl, smd = TRUE)

```

SMDs are \< 0.1 which means we can move forward.

## Check positivity assumption

::: panel-tabset
### Graphic

```{r propscore31}
#| message: false
#| echo: false

# Positivity assumption checking
# Is there overlap between propensity scores in control and treated?
ggplot2::ggplot(final_match, aes(x = prop_score)) +
  geom_density(data = final_match %>% 
                 filter(Heating == TRUE), 
               aes(x = prop_score, y = ..density..), fill= "#69b3a2") +
  geom_density(data = final_match %>% 
                 filter(Heating == FALSE), 
               aes(x = prop_score, y = -..density..), fill= "#404080") +
  theme_minimal() +
  xlab('Propensity Score') +
  ylab('Density')
```

Looks good; we have overlap across the distribution.

### Code

```{r propscore32}
#| message: false
#| echo: true
#| eval: false

# Positivity assumption checking: 
# Is there overlap between propensity scores in control and treated?
ggplot2::ggplot(data = final_match, 
                mapping = aes(x = prop_score)) +
  ggplot2::geom_density(
    data = final_match %>% dplyr::filter(Heating == TRUE), 
    mapping = aes(x = prop_score, y = ..density..), 
    fill = "#69b3a2") +
  ggplot2::geom_density(
    data = final_match %>% dplyr::filter(Heating == FALSE), 
    mapping = aes(x = prop_score, y = -..density..), 
    fill = "#404080") +
  ggplot2::theme_minimal() +
  ggplot2::xlab('Propensity Score') +
  ggplot2::ylab('Density')

```
:::

## Run statistical inference

```{r propscore5}
#| message: false

# Vector of prices for heating (treatment) group
y_trt <- final_match %>% 
  dplyr::filter(Heating == TRUE) %>% 
  dplyr::pull(price)

# Vector of prices for heating (control) group
y_con <- final_match %>% 
  dplyr::filter(Heating == FALSE) %>% 
  dplyr::pull(price)

t.test(y_trt, y_con, paired = TRUE, 
       alternative = 'two.sided',
       mu = 0, 
       var.equal = FALSE,
       conf.level = 0.95)

```