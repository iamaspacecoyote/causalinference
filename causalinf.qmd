---
title: "Taking a Leap of Faith: Association to Causation"
author: "Lindsey Dietz, PhD"
date: "`r Sys.Date()`"
format: 
  revealjs:
    incremental: true  
    theme: dark
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Coffee

How many of you drink coffee?

. . .

How many of you think it is bad for you?

. . .

*"The **risk** of hypertension associated with coffee intake varies according to CYP1A2 genotype. Carriers of slow 1F allele are at **increased risk** and should thus abstain from coffee, whereas individuals with 1A/1A genotype can safely drink coffee."*

-- Journal of Hypertension, August 2009

## Coffee

How many of you drink coffee?

How many of you think it is good for you?

. . .

*"Drinking two to three cups of coffee a day is **linked with a longer lifespan and lower risk** of cardiovascular disease compared with avoiding coffee."*

-- European Journal of Preventive Cardiology, September 2022

##  {background-iframe="https://giphy.com/embed/UnTC9o2HMyUta" background-repeat="a\"repeat\""}

## Agenda

-   Causal Inference Preliminaries
-   Matching
-   Example using R and Airbnb Data

## Association To Causation

-   Most researchers want to understand more than just association (a.k.a links, risks, etc.)
-   For example,
    -   Will a new feature increase revenue in my app?
    -   Does a vaccine prevent the flu?
    -   Will a regulatory policy change impact bank capital?

## Causal Inference

Causal inference is a general set of principles and methods that allow us to make statistical inferences about the causal effects of treatments from randomized and observational data.

::: fragment
*Did she just say I can make causal statements from observational data?*

<center><img src="https://media.giphy.com/media/5SXsDXvfhx2eI/giphy.gif" width="400"/></center>
:::

## The 'Leap of Faith'

Well, sort of...

We must make **strong and mostly untestable** assumptions about the treatment assignment mechanism to go from descriptive to causal inference for observational data.

## Those who can, design experiments!

::: columns
::: {.column width="30%"}
<center><img src="https://media.giphy.com/media/vnELlPo3FyzfO/giphy.gif" width="500"/></center>
:::

::: {.column width="70%"}
-   Randomized Experiments a.k.a *Randomized Controlled Trials (RCTs)* or *A/B testing* are the gold standard for causation.
-   However, ethical or logistical reasons may prevent us from using experimentation.
    -   We cannot force people to do dangerous things.
    -   If one unit is influenced by another, we cannot parse treatment impacts.
:::
:::

## Neyman--Rubin Causal Model

-   Aside from a randomized experiment, causal inference is a missing data problem.

-   We don't know the real-world probability of a unit being assigned into a treatment ($T$) given a set of confounders ($X$).

## Potential Outcomes Framework

Each unit has *potential* outcomes $\{Y_0, Y_1\}$ before a treatment decisions is made. A *counterfactual* outcome is what would have been observed if the treatment had been different.

![](images/outcomes.png){fig-align="center"}

## Fundamental problem of causal inference

We cannot observe both potential outcomes for a unit.

![](images/observed.png){fig-align="center"}

## Average Treatment Effect (ATE)

Average of all treatment potential outcomes − Average of all control potential outcomes

${ATE} = E[Y_{1} − Y_{0}]$

In general, $E[Y_{1} − Y_{0}] \ne E[Y|T=1] − E[Y|T=0]$.

This is a difference between setting and conditioning (though the notation appears to be identical!)

$E[Y|T=1]$: mean of Y among units with T = 1

$E[Y_1]$: mean of Y if the whole population was treated with T = 1

Key idea: estimating the counterfactual --- a prediction of what would have happened in the absence of the treatment.

## Positivity Assumption

<center><img src="https://media.giphy.com/media/zRwA2JgARLVYgWtfgY/giphy.gif" width="800"/></center>

## Positivity Assumption

-   English: Conditional on confounders, every experimental unit is equally likely to be assigned a treatment.

-   Probabilistic: $P(T = t | X = x) > 0$.

-   Why: If some segment of the population has no chance of being assigned a treatment, there is no counterfactual to estimate.

## Ignorability Assumption

<center><img src="https://media.giphy.com/media/IdmfEtnMWPzOg/giphy.gif" width="1000"/></center>

## Ignorability Assumption

-   English: There are no unmeasured confounders.

-   Probabilistic: $Y_0, Y_1 \perp T | X$.

-   Why: Among those with the same confounders, we can assume the treatment has been randomly assigned.

## Consistency Assumption

<center><img src="https://media.giphy.com/media/fvT2tuQGmYxsQbSrQH/giphy.gif" width="1000"/></center>

## Consistency Assumption

-   English: Each outcome is observable.

-   Probabilistic: $Y = Y_t$ if $T = t$ for all $t$. This implies, $P(Y|T=t) = P(Y_t|T=t)$.

-   Why:

## Stable Unit Treatment Value Assumption (SUTVA)

<center><img src="https://media.giphy.com/media/ailnj2AMt9e9i/giphy.gif" width="800"/></center>

## Stable Unit Treatment Value Assumption (SUTVA)

-   Potential outcomes for unit i are unaffected by the treatment assignment for unit j.

## How assumptions get us to the ATE

\begin{tabular}{ c | c | c }
Y & T & X \\
 \hline \\
10 & T & X \\
8 & T & X \\
7 & T & X \\
4 & T & X 
\end{tabular}

$E[Y|T=t, X=x]$ involves only observed data.

|Unit | Y | T | X |
|---:|---:|--:|:------|
|1 | 10 | 1 | 1 | 
|2 | 7  | 1 | 1 |
|3 | 8  | 0 | 1 | 
|4 | 5  | 0 | 1 |

$E[Y|T=1, X=1] = \frac{10 + 7}{2} = 8.5$
$E[Y|T=0, X=1] = \frac{8 + 5}{2} = 6.5$

## How assumptions get us to the ATE

\begin{align}
E[Y|T=t, X=x] =& E[Y_t|T=t, X=x] \text{ by Consistency}\\
=& E[Y_t|X=x] \text{ by Ignorability}\\
\end{align}

::: fragment
$E[Y_t] = E[E[Y_t|X=x]]$ by the Law of Total Expectation
:::

::: fragment
Then, \begin{align}
E[Y_1 - Y_0] =& E[Y_1] - E[Y_0] \\
=& E[E[Y_1|X=x]] - E[E[Y_0|X=x]]
\end{align}
:::

## Propensity Scores & Matching

-   In a randomized experiment, $P(T=1|X) = P(T=1) = 0.5$.

-   In most observational data sets, there was no random assignment of the treatment $P(T=1|X) = f(X)$. However, we can estimate $f(X)$ with data and assumptions about which $X$ matter.

    -   Ex. a unit with predicted propensity score of 0.3 has a 30% chance of receiving treatment.

-   Once we match on propensity score, we can meet our assumption of *Ignorability*.

## Matching in Practice

1.  Fit a propensity score model for treatment: $P(T=1|X) = f(X)$
    -   binary outcome =\> logistic regression or machine learning alternatives
2.  Use the model to predict a propensity score for each observation.
3.  Match observations based on a selected algorithm.
    -   Choice of distance to optimize
    -   Choice of maximum distance
4.  Use matched outcomes in statistical inference

## Airbnb Data Example

Will adding heating in Minneapolis-St. Paul Airbnb listings lead to increased revenue per stay?

-   Treatment: Heating present
-   Control: Heating absent
-   Unit: Unique listing
-   Outcome: Nightly cost
-   Plausible Confounders: \# of bedrooms, \# of bathrooms, type of listing (Private Room vs. Entire home). *Please note there are many many other confounders possible that I'm not including for simplicity.*

## Setting up libraries and reading in data

```{r dataclean}
#| message: false
#| cache: true

library(dplyr)
library(tidyr)
library(stringr)
library(MatchIt)
library(tableone)
library(data.table)
library(ggplot2)

# Custom functions for this analysis
source('support_functions.R')

# http://insideairbnb.com/get-the-data
msp <- reading_data(url = "http://data.insideairbnb.com/united-states/mn/twin-cities-msa/2022-09-16/data/listings.csv.gz")

```

## Data Cleaning and Review {auto-animate="true"}

```{r}
#| message: false
#| cache: true

# Custom function to get top n amenities for simplicity
top40msp <- top_amenities(data = msp, number = 40) 

# Custom function to apply filters and pre-processing
analysis_set_msp <- create_analysis_set(
                      data = msp, 
                      amenities_vector = top40msp, 
                      test_var = 'Heating',
                      inactive_date = as.Date('2022-04-30'),
                      room_types = c('Entire home/apt', 'Private room'),
                      standard_baths = 1:3,
                      standard_beds = 0:5,
                      review_lower_bound = 0,
                      min_nights_upper_bound = 7)
```

## Data Cleaning and Review {auto-animate="true"}

```{r}
#| message: false
#| cache: true

# Custom function to get top n amenities for simplicity
top40msp <- top_amenities(data = msp, number = 40) 

# Custom function to apply filters and pre-processing
analysis_set_msp <- create_analysis_set(
                      data = msp, 
                      amenities_vector = top40msp, 
                      test_var = 'Heating',
                      inactive_date = Sys.Date() - 365,
                      room_types = c('Entire home/apt', 'Private room'),
                      standard_baths = 1:3,
                      standard_beds = 0:5,
                      review_lower_bound = 0,
                      min_nights_upper_bound = 7)

unmatched_tbl <- tableone::CreateTableOne(
                         vars = c('beds', 'bathroom', 'room_type'),
                         data = analysis_set_msp, 
                         strata = 'Heating', 
                         smd = TRUE, 
                         test = FALSE)

print(unmatched_tbl, smd = TRUE)

```

## Standardized Mean Differences (SMD)

The SMD is a measure of distance between two group means in terms of one or more variables.

-   Continuous variables: $SMD = \frac{\bar{x}_t - \bar{x}_c}{\sqrt{\frac{s_t^2 + s_c^2}{2}}}$

-   Binary variables: $SMD = \frac{\hat{p}_t - \hat{p}_c}{\sqrt{\frac{p_t(1-p_t) + p_c(1-p_c)}{2}}}$

-   Heuristic: SMD \< 0.1 indicates a negligible difference in the mean or prevalence of a covariate between groups.

::: fragment
```{r}
#| message: false
#| cache: true
#| echo: false
print(unmatched_tbl, smd = TRUE)

```
:::

## Fit a propensity score model and conduct matching {auto-animate="true"}

```{r propscore1}
#| message: false
#| cache: true

matched_out <- MatchIt::matchit(Heating ~ beds + bathroom + room_type, 
                                data = analysis_set_msp, 
                                method = 'optimal',
                                caliper = NULL)

analysis_set_msp <- analysis_set_msp %>%
  dplyr::mutate(prop_score = matched_out$model$fitted.values,
                weights = matched_out$weights) %>%
  dplyr::arrange(desc(weights), desc(price))
```

## Fit a propensity score model and conduct matching {auto-animate="true"}

```{r propscore2}
#| message: false
#| cache: true

matched_out <- MatchIt::matchit(Heating ~ beds + bathroom + room_type, 
                                data = analysis_set_msp, 
                                method = 'optimal',
                                caliper = NULL)

analysis_set_msp <- analysis_set_msp %>%
  dplyr::mutate(prop_score = matched_out$model$fitted.values,
                weights = matched_out$weights) %>%
  dplyr::arrange(desc(weights), desc(price))

analysis_set_msp
```

## Check positivity assumption

::: panel-tabset
### Graphic

```{r propscore31}
#| message: false
#| cache: true
#| echo: false

# Positivity assumption checking
# Is there overlap between propensity scores in control and treated?
ggplot2::ggplot(analysis_set_msp, aes(x = prop_score)) +
  geom_density(data = analysis_set_msp %>% 
                 filter(Heating == TRUE), 
               aes(x = prop_score, y = ..density..), fill= "#69b3a2") +
  geom_density(data = analysis_set_msp %>% 
                 filter(Heating == FALSE), 
               aes(x = prop_score, y = -..density..), fill= "#404080") +
  theme_minimal() +
  xlab('Propensity Score') +
  ylab('Density')
```

Seems like we are in good shape since we have overlap across the distribution.

### Code

```{r propscore32}
#| message: false
#| cache: true
#| echo: true
#| eval: false

# Positivity assumption checking: 
# Is there overlap between propensity scores in control and treated?
ggplot2::ggplot(data = analysis_set_msp, 
                mapping = aes(x = prop_score)) +
  ggplot2::geom_density(
    data = analysis_set_msp %>% dplyr::filter(Heating == TRUE), 
    mapping = aes(x = prop_score, y = ..density..), 
    fill = "#69b3a2") +
  ggplot2::geom_density(
    data = analysis_set_msp %>% dplyr::filter(Heating == FALSE), 
    mapping = aes(x = prop_score, y = -..density..), 
    fill = "#404080") +
  ggplot2::theme_minimal() +
  ggplot2::xlab('Propensity Score') +
  ggplot2::ylab('Density')

```
:::

## Review outcome of matching

```{r propscore4}
#| message: false
#| cache: true

matched_set_msp <- analysis_set_msp %>%
  dplyr::filter(weights == 1) %>%
  dplyr::select(-weights, -prop_score)

match_tbl <- tableone::CreateTableOne(
                    vars = c('beds', 'bathroom', 'room_type'), 
                    data = matched_set_msp,
                    strata = 'Heating',
                    smd = TRUE, 
                    test = FALSE)

print(match_tbl, smd = TRUE)

```

SMDs are \< 0.1 which means we can move forward.

## Complete outcome analysis on matched data

```{r propscore5}
#| message: false
#| cache: true

# Vector of prices for heating (treatment) group
y_trt <- matched_set_msp %>%
  dplyr::filter(Heating == TRUE) %>%
  dplyr::pull(price)

# Vector of prices for heating (control) group
y_con <- matched_set_msp %>%
  dplyr::filter(Heating == FALSE) %>%
  dplyr::pull(price)

t.test(y_trt, y_con, 
       paired = TRUE, 
       alternative = 'greater',
       mu = 0, 
       var.equal = FALSE,
       conf.level = 0.95)

```
