---
title: "Taking a Leap of Faith: Association to Causation"
author: "Lindsey Dietz, PhD"
date: "`r Sys.Date()`"
format: 
  revealjs:
    incremental: true  
    theme: dark
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Coffee

How many of you drink coffee?

. . .

How many of you think it is bad for you?

. . .

*"The **risk** of hypertension associated with coffee intake varies according to CYP1A2 genotype. Carriers of slow 1F allele are at **increased risk** and should thus abstain from coffee, whereas individuals with 1A/1A genotype can safely drink coffee."*

-- Journal of Hypertension, August 2009

## Coffee

How many of you drink coffee?

How many of you think it is good for you?

. . .

*"Drinking two to three cups of coffee a day is **linked with a longer lifespan and lower risk** of cardiovascular disease compared with avoiding coffee."*

-- European Journal of Preventive Cardiology, September 2022

##  {background-iframe="https://giphy.com/embed/UnTC9o2HMyUta" background-repeat=a"repeat"}

## Agenda

-   Causal Inference Preliminaries
-   Matching
-   Example using R and Airbnb Data

## Association To Causation

-   Most researchers want to understand more than just association (a.k.a links, risks, etc.)
-   For example,
    -   Will a new feature increase revenue in my app?
    -   Does a vaccine prevent the flu?
    -   Will a regulatory policy change impact bank capital?

## Causal Inference

::: columns
::: {.column width="70%"}

Causal inference is a general set of principles and methods that allow us to make statistical inferences about the causal effects of treatments from randomized and **observational** data.
:::

::: {.column width="30%"}
<iframe height="600" data-src="https://giphy.com/embed/5SXsDXvfhx2eI"
align="top">
</iframe>
:::
:::

## Those who can, design experiments!

::: columns
::: {.column width="30%"}
<iframe height="500" data-src="https://giphy.com/embed/vnELlPo3FyzfO">

</iframe>
:::

::: {.column width="70%"}
-   Randomized Experiments a.k.a *Randomized Controlled Trials (RCTs)* or *A/B testing* are the gold standard for causation.
-   However, ethical or logistical reasons may prevent us from using experimentation.
    -   We cannot force people to do dangerous things.
    -   If one unit is influenced by another, we cannot parse treatment impacts.
:::
:::

## Neyman--Rubin Causal Model

- Aside from a randomized experiment, causal inference is a missing data problem. 

- We don't know the real-world probability of a unit being assigned into a treatment ($T$) given a set of confounders ($X$).

## Potential Outcomes Framework

Each unit has *potential* outcomes $\{Y_0, Y_1\}$ before a treatment decisions is made. A *counterfactual* outcome is what would have been observed if the treatment had been different.

![](images/outcomes.png){fig-align="center"}

## Fundamental problem of causal inference

We cannot observe both potential outcomes for a unit.

![](images/observed.png){fig-align="center"}

## Average Treatment Effect (ATE)

Average of all treatment potential outcomes − Average of all control potential outcomes

${ATE} = E[Y_{1} − Y_{0}]$

In general, $E[Y_{1} − Y_{0}] \ne E[Y|T=1] − E[Y|T=0]$. 

This is a difference between setting and conditioning (though the notation appears to be identical!)

$E[Y|T=1]$: mean of Y among units with T = 1

$E[Y_1]$: mean of Y if the whole population was treated with T = 1

Key idea: estimating the counterfactual --- a prediction of what would have happened in the absence of the treatment.

## The 'Leap of Faith'

- We must make **strong and mostly untestable** assumptions about the treatment assignment mechanism to go from descriptive to causal inference.

- I've already glossed over a few assumptions on my descriptions so far. Let's walk through the four key assumptions.

## Positivity Assumption

- English: Every experimental unit is equally likely to be assigned a treatment conditional on confounders

- Probabilistic: $P(T = t | X = x) > 0$.

- Why: If some segment of the population has no chance of being assigned a treatment, there is no counterfactual to estimate.

<iframe height="360" src="https://giphy.com/embed/zRwA2JgARLVYgWtfgY/video" width="480"></iframe>

## Ignorability Assumption

- English: There are no unmeasured confounders. 

- Probabilistic: $Y_0, Y_1 \perp T | X$. 

- Why: Among those with the same confounders, we can assume the treatment has been randomly assigned.

<iframe src="https://giphy.com/embed/IdmfEtnMWPzOg" width="480" height="273" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>

## Consistency Assumption

- English: Each outcome is observable.

- Probabilistic: $Y = Y_t$ if $T = t$ for all $t$.

- Why: 

<iframe src="https://giphy.com/embed/fvT2tuQGmYxsQbSrQH" width="480" height="295" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>

## Stable Unit Treatment Value Assumption (SUTVA)

- Potential outcomes for unit i are unaffected by the treatment assignment for unit j.

<iframe width="1000" data-src="https://giphy.com/embed/ailnj2AMt9e9i" ></iframe>

## How assumptions get us to the ATE

$E[Y|T=t, X=x]$ involves only observed data.

```{=tex}
\begin{align}
E[Y|T=t, X=x] =& E[Y_t|T=t, X=x] \text{ by Consistency}\\
=& E[Y_t|X=x] \text{ by Ignorability}\\
\end{align}
```
$E[Y_t] = E[E[Y_t|X=x]]$ by the Law of Total Expectation

Then, \begin{align}
E[Y_1 - Y_0] =& E[Y_1] - E[Y_0] \\
=& E[E[Y_1|X=x]] - E[E[Y_0|X=x]]
\end{align}

## Matching

Suppose we are not in control of the treatment mechanism so there are differences in the assignment, i.e. we are in violation of the Ignorability and possibly the Positivity assumption.

We want to match on the full set of covariates, X. Propensity scoring: For unit i, $\pi_i = P(T=t|X=x_i)$ If a unit has a propensity score of 0.3, they would have a 30% chance of receiving treatment.

If we match on propensity score, we can meet our assumption of ignorability (treatment is randomized given X).

In a randomized experiment, $P(T=1\|X) = P(T=1) = 0.5$. In an observational setting, we don't know the score, but we can estimate it.

## Matching in Practice

P(T=1\|X) - we have a binary outcome so we can use methods that are suitable for this such as logistic regression (or machine learning alternatives).

1.  Fit a propensity score model with outcome T and covariates X.
2.  Get the predicted propensity score for each unit.
3.  Perform matching based on an algorithm

Overlap between propensity scores in control and treated: Positivity assumption checking $P(T = t | X = x) > 0$

Match on distance- caliper to prevent bad matches

## Airbnb Data Example

Will adding heating in Minneapolis-St. Paul Airbnb listings lead to increased revenue per stay?

-   Treatment: Heating present
-   Control: Heating absent
-   Experimental Unit: Listing
-   Measurement/Metric: Nightly cost
-   Plausible Confounders: # of bedrooms, # of bathrooms, type of listing (Private Room vs. Entire home). *Please note there are many many other confounders possible that I'm not including for simplicity.*

## Setting up libraries and reading in data

```{r dataclean}
#| message: false
#| cache: true

library(dplyr)
library(tidyr)
library(stringr)
library(MatchIt)
library(tableone)
library(data.table)
library(ggplot2)

source('support_functions.R')

# http://insideairbnb.com/get-the-data
msp <- reading_data(url = "http://data.insideairbnb.com/united-states/mn/twin-cities-msa/2022-09-16/data/listings.csv.gz")

```

## Data Cleaning and Review

```{r dataclean2}
#| message: false
#| cache: true

# Custom function to get top n amenities for simplicity
top40msp <- top_amenities(data = msp, number = 40) 

# Custom function to apply filters and pre-processing
analysis_set_msp <- create_analysis_set(
                      data = msp, 
                      amenities_vector = top40msp, 
                      test_var = 'Heating',
                      inactive_date = Sys.Date() - 365,
                      room_types = c('Entire home/apt', 'Private room'),
                      standard_baths = 1:3,
                      standard_beds = 0:5,
                      review_lower_bound = 0,
                      min_nights_upper_bound = 7)

unmatched_tbl <- tableone::CreateTableOne(
                         vars = c('beds', 'bathroom', 'room_type'),
                         data = analysis_set_msp, 
                         strata = 'Heating', 
                         smd = TRUE, 
                         test = FALSE)

print(unmatched_tbl, smd = TRUE)

```

## Standardized Mean Differences (SMD)

The SMD is a measure of distance between two group means in terms of one or more variables.

 - Continuous variables: $SMD = \frac{\bar{x}_t - \bar{x}_c}{\sqrt{\frac{s_t^2 + s_c^2}{2}}}$

 - Binary variables: $SMD = \frac{\hat{p}_t - \hat{p}_c}{\sqrt{\frac{p_t(1-p_t) + p_c(1-p_c)}{2}}}$

- Heuristic: SMD < 0.1 indicates a negligible difference in the mean or prevalence of a covariate between groups.

::: {.fragment}

```{r} 
#| message: false
#| cache: true
#| echo: false
print(unmatched_tbl, smd = TRUE)

```
::: 


## Fit a propensity score model and conduct matching

```{r propscore}
#| message: false
#| cache: true

matched_out <- MatchIt::matchit(Heating ~ beds + bathroom + room_type, 
                                data = analysis_set_msp, 
                                method = 'optimal',
                                caliper = NULL)

analysis_set_msp <- analysis_set_msp %>%
  dplyr::mutate(prop_score = matched_out$model$fitted.values,
                weights = matched_out$weights) %>%
  dplyr::arrange(desc(weights), desc(price))

analysis_set_msp
```

## Check positivity assumption

::: panel-tabset
### Graphic

```{r propscore31}
#| message: false
#| cache: true
#| echo: false

# Positivity assumption checking
# Is there overlap between propensity scores in control and treated?
ggplot2::ggplot(analysis_set_msp, aes(x = prop_score)) +
  geom_density(data = analysis_set_msp %>% 
                 filter(Heating == TRUE), 
               aes(x = prop_score, y = ..density..), fill= "#69b3a2") +
  geom_density(data = analysis_set_msp %>% 
                 filter(Heating == FALSE), 
               aes(x = prop_score, y = -..density..), fill= "#404080") +
  theme_minimal() +
  xlab('Propensity Score') +
  ylab('Density')
```

Looks like we are in good shape since we have overlap across the distribution.

### Code

```{r propscore32}
#| message: false
#| cache: true
#| echo: true
#| eval: false

# Positivity assumption checking: 
# Is there overlap between propensity scores in control and treated?
ggplot2::ggplot(analysis_set_msp, aes(x = prop_score)) +
  geom_density(data = analysis_set_msp %>% 
                 filter(Heating == TRUE), 
               aes(x = prop_score, y = ..density..), fill= "#69b3a2") +
  geom_density(data = analysis_set_msp %>% 
                 filter(Heating == FALSE), 
               aes(x = prop_score, y = -..density..), fill= "#404080") +
  theme_minimal() +
  xlab('Propensity Score') +
  ylab('Density')
```
:::

## Review outcome of matching

```{r propscore4}
#| message: false
#| cache: true

matched_set_msp <- analysis_set_msp %>%
  dplyr::filter(weights == 1) %>%
  dplyr::select(-weights, -prop_score)

match_tbl <- tableone::CreateTableOne(
                    vars = c('beds', 'bathroom', 'room_type'), 
                    data = matched_set_msp,
                    strata = 'Heating',
                    smd = TRUE, 
                    test = FALSE)

print(match_tbl, smd = TRUE)

```

SMDs are all below 0.1 which puts us in good shape to move forward.

## Complete outcome analysis on matched data

```{r propscore5}
#| message: false
#| cache: true

# Vector of prices for heating (treatment) group
y_trt <- matched_set_msp %>%
  dplyr::filter(Heating == TRUE) %>%
  dplyr::pull(price)

# Vector of prices for heating (control) group
y_con <- matched_set_msp %>%
  dplyr::filter(Heating == FALSE) %>%
  dplyr::pull(price)

t.test(y_trt, y_con, paired = TRUE)

```
